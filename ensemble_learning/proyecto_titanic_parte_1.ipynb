{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proyecto_titanic_parte_1.ipynb",
      "provenance": [],
      "mount_file_id": "1ICSditewY-YJII_M11S377S2WuDRM1_E",
      "authorship_tag": "ABX9TyPI/NiM9EG/wZ/kFMDSFt2F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cavendano01/Statistical-Learning-I/blob/main/ensemble_learning/proyecto_titanic_parte_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPHZzNLF0XAz"
      },
      "source": [
        "# Parte 1: Entrenamiento y validación y selección\n",
        "(Nivel de exactitud mínimo deseado: 80%)\n",
        "\n",
        "**Nota:** \n",
        "\n",
        "En los casos en donde se deba calcular métricas de evaluación,con objetivos de simplificar el problema se puede usar cualquier herramienta , por ejemplo sklearn en el subpaquete metrics:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpCQalLu7UtZ"
      },
      "source": [
        "## Preparación de Notebook & Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWkO_h-37HJp"
      },
      "source": [
        "### Agregando Librerías requeridas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_8XMr0oyqwK",
        "outputId": "8f07e54d-6178-4943-afe3-4c431ed9de14"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np # Data Manipulation & Naive Bayes\n",
        "import matplotlib.pyplot as plt #Data Exploration\n",
        "import tensorflow as tf #Logistic Regression\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz #SkLearn decission Tree\n",
        "# https://github.com/andressa/sklearn-decisiontree/blob/master/Ensemble%20models%20with%20Decision%20Trees.ipynb\n",
        "from sklearn import svm #Import svm model\n",
        "# https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python\n",
        "\n",
        "from sklearn.model_selection import train_test_split # Spliting Data \n",
        "print (\"Packages Loaded\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn import model_selection\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Packages Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9oe2sQ965as"
      },
      "source": [
        "### Ajustando TF para compatibilidad con TF1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2OLMKd7648q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c005499f-253c-48b5-a123-92ec68a23d94"
      },
      "source": [
        "if tf.__version__.startswith(\"2.\"):\n",
        "  import tensorflow.compat.v1 as tf\n",
        "  tf.compat.v1.disable_v2_behavior()\n",
        "  tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfwK5D_Y6_3P"
      },
      "source": [
        "### Cargando dataset como array de numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVbUPFOH8Bt8",
        "outputId": "8f6e5746-c8fe-46dd-a71d-4e0d1aaca0fc"
      },
      "source": [
        "#Data Loading\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4ZVlMWy7QFL"
      },
      "source": [
        "titanic =pd.read_csv(\"/content/drive/MyDrive/Statistical Learning O/proyecto_final/data_titanic_proyecto.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk0U9Ckq-BhF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "mzhvyx_j-iPH",
        "outputId": "d09bd40e-aada-45b2-f47c-a2bfc9144eca"
      },
      "source": [
        "titanic.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>passenger_class</th>\n",
              "      <th>passenger_sex</th>\n",
              "      <th>passenger_survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>Lower</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "      <td>Upper</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>Lower</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "      <td>Upper</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>Lower</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Moran, Mr. James</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330877</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "      <td>Lower</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>McCarthy, Mr. Timothy J</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17463</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>E46</td>\n",
              "      <td>S</td>\n",
              "      <td>Upper</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Palsson, Master. Gosta Leonard</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>349909</td>\n",
              "      <td>21.0750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>Lower</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>347742</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>Lower</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>237736</td>\n",
              "      <td>30.0708</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>Middle</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  ... passenger_survived\n",
              "0            1  ...                  N\n",
              "1            2  ...                  Y\n",
              "2            3  ...                  Y\n",
              "3            4  ...                  Y\n",
              "4            5  ...                  N\n",
              "5            6  ...                  N\n",
              "6            7  ...                  N\n",
              "7            8  ...                  N\n",
              "8            9  ...                  Y\n",
              "9           10  ...                  Y\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znHE8J5DAY7y",
        "outputId": "63553898-170f-4269-da04-9cee428f13ab"
      },
      "source": [
        "#Count the number of rows and columns in the data set \n",
        "titanic.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "p_EfBlxZAeqy",
        "outputId": "6348b21e-6228-4fa2-e346-c64a88723f45"
      },
      "source": [
        "titanic.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId         Age       SibSp       Parch        Fare\n",
              "count   891.000000  714.000000  891.000000  891.000000  891.000000\n",
              "mean    446.000000   29.699118    0.523008    0.381594   32.204208\n",
              "std     257.353842   14.526497    1.102743    0.806057   49.693429\n",
              "min       1.000000    0.420000    0.000000    0.000000    0.000000\n",
              "25%     223.500000   20.125000    0.000000    0.000000    7.910400\n",
              "50%     446.000000   28.000000    0.000000    0.000000   14.454200\n",
              "75%     668.500000   38.000000    1.000000    0.000000   31.000000\n",
              "max     891.000000   80.000000    8.000000    6.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIiqawbhD9fi"
      },
      "source": [
        "## Feature Engineering "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEyhUDSVEWkF"
      },
      "source": [
        "### Lidiando con NAs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNZszR86EZo3",
        "outputId": "dadad6cc-1216-42f7-a92c-afe32c65d16f"
      },
      "source": [
        "titanic.isna().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId             0\n",
              "Name                    0\n",
              "Age                   177\n",
              "SibSp                   0\n",
              "Parch                   0\n",
              "Ticket                  0\n",
              "Fare                    0\n",
              "Cabin                 687\n",
              "Embarked                2\n",
              "passenger_class         0\n",
              "passenger_sex           0\n",
              "passenger_survived      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uF07rCcE-3G"
      },
      "source": [
        "#### Columna Cabin\n",
        "Ya que existen 687 datos, utilizar imputación de promedio puede sesgar el dataset, especialemtne ya que tenemos una idea de la categoría del boleto. Procedemos a eliminar columna de análisis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BETTZz5E-mW",
        "outputId": "d1747935-070e-41e1-995d-8cc5c8be14cf"
      },
      "source": [
        "titanic = titanic.drop(['Cabin'], axis=1)\n",
        "titanic.isna().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId             0\n",
              "Name                    0\n",
              "Age                   177\n",
              "SibSp                   0\n",
              "Parch                   0\n",
              "Ticket                  0\n",
              "Fare                    0\n",
              "Embarked                2\n",
              "passenger_class         0\n",
              "passenger_sex           0\n",
              "passenger_survived      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXVbM648FdcN"
      },
      "source": [
        "#### Columna Age \n",
        "Tenemos 177 resultados de Age que tenemos que cambiar, para no perder las demás características en el modelo imputaremos la edad promedio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL6o_bBqFbpH",
        "outputId": "e2b256a8-ed03-431c-d802-3cf056adcec0"
      },
      "source": [
        "titanic = titanic.fillna(titanic.mean())\n",
        "titanic.isna().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId           0\n",
              "Name                  0\n",
              "Age                   0\n",
              "SibSp                 0\n",
              "Parch                 0\n",
              "Ticket                0\n",
              "Fare                  0\n",
              "Embarked              2\n",
              "passenger_class       0\n",
              "passenger_sex         0\n",
              "passenger_survived    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzsN0aAoErpn"
      },
      "source": [
        "### Lidiando con columnas No Numéericas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSf9SGEHEwcg",
        "outputId": "4482e4ac-69ec-4ecd-bf3c-581ffde64a64"
      },
      "source": [
        "titanic.dtypes"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId             int64\n",
              "Name                   object\n",
              "Age                   float64\n",
              "SibSp                   int64\n",
              "Parch                   int64\n",
              "Ticket                 object\n",
              "Fare                  float64\n",
              "Embarked               object\n",
              "passenger_class        object\n",
              "passenger_sex          object\n",
              "passenger_survived     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGMPllndE3Sf"
      },
      "source": [
        "ya que tenemos atributos como Sexo y edad, el nombre de una persona es redundante , pudiera ser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0wOBhaUE2_Q"
      },
      "source": [
        "#titanic = titanic.drop(['Cabin'], axis=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj5cUDNkG1JC"
      },
      "source": [
        "### Variable Encoding: \n",
        "* Embarked, \n",
        "* passenger_sex \n",
        "* passenger_class\n",
        "* Passenger_survived"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkN4kw2RDpdO"
      },
      "source": [
        "#Encode embarked\n",
        "titanic['Embarked'] = titanic['Embarked'].astype('str') \n",
        "titanic.iloc[:,7]= labelencoder.fit_transform(titanic.iloc[:,7].values)\n",
        "#print(labelencoder.fit_transform(titanic.iloc[:,7].values))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBaB10IoA0Ya"
      },
      "source": [
        "#Encoding Sex como 0 y 1\n",
        "titanic.iloc[:,9]= labelencoder.fit_transform(titanic.iloc[:,9].values)\n",
        "#print(labelencoder.fit_transform(titanic.iloc[:,2].values))\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRSZf_8jG02t"
      },
      "source": [
        "#Encode passenger_class\n",
        "titanic['passenger_class'] = titanic['passenger_class'].astype('str') \n",
        "titanic.iloc[:,8]= labelencoder.fit_transform(titanic.iloc[:,8].values)\n",
        "#print(labelencoder.fit_transform(titanic.iloc[:,7].values))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2xzoa6nHWZo"
      },
      "source": [
        "#Encode Passenger_survived\n",
        "titanic['passenger_survived'] = titanic['passenger_survived'].astype('str') \n",
        "titanic.iloc[:,10]= labelencoder.fit_transform(titanic.iloc[:,10].values)\n",
        "#print(labelencoder.fit_transform(titanic.iloc[:,7].values))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMLdXvFaHWNS",
        "outputId": "e45ca09e-3714-4f2f-8b14-57f1ca45eba9"
      },
      "source": [
        "#Print the NEW unique values in the columns\n",
        "print(titanic['passenger_sex'].unique())\n",
        "print(titanic['Embarked'].unique())\n",
        "print(titanic['passenger_class'].unique())\n",
        "print(titanic['passenger_survived'].unique())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0]\n",
            "[2 0 1 3]\n",
            "[0 2 1]\n",
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiIPlnRIIfrs",
        "outputId": "b833e533-cb7f-4525-8619-18c91e1f8438"
      },
      "source": [
        "titanic.dtypes"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId             int64\n",
              "Name                   object\n",
              "Age                   float64\n",
              "SibSp                   int64\n",
              "Parch                   int64\n",
              "Ticket                 object\n",
              "Fare                  float64\n",
              "Embarked                int64\n",
              "passenger_class         int64\n",
              "passenger_sex           int64\n",
              "passenger_survived      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF04zkWyUfRf"
      },
      "source": [
        "### Additional checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V60AP91UdKY",
        "outputId": "a8b86cbf-eb35-48d6-a8ab-c12d442189a2"
      },
      "source": [
        "titanic.isna().sum()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId           0\n",
              "Name                  0\n",
              "Age                   0\n",
              "SibSp                 0\n",
              "Parch                 0\n",
              "Ticket                0\n",
              "Fare                  0\n",
              "Embarked              0\n",
              "passenger_class       0\n",
              "passenger_sex         0\n",
              "passenger_survived    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR0kh-GjY8cv",
        "outputId": "20c30d3d-b7ca-49f4-b992-3e6c69e1f7fd"
      },
      "source": [
        "titanic.dtypes"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId             int64\n",
              "Name                   object\n",
              "Age                   float64\n",
              "SibSp                   int64\n",
              "Parch                   int64\n",
              "Ticket                 object\n",
              "Fare                  float64\n",
              "Embarked                int64\n",
              "passenger_class         int64\n",
              "passenger_sex           int64\n",
              "passenger_survived      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGwFTsElZGqu"
      },
      "source": [
        "#### Drop de Tickets ya que no posee valore repetitivos a encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mmHFeEHY_wP",
        "outputId": "8716c111-1194-483d-dfd2-4b8bac66679b"
      },
      "source": [
        "titanic = titanic.drop(['Ticket'], axis=1)\n",
        "titanic.dtypes"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId             int64\n",
              "Name                   object\n",
              "Age                   float64\n",
              "SibSp                   int64\n",
              "Parch                   int64\n",
              "Fare                  float64\n",
              "Embarked                int64\n",
              "passenger_class         int64\n",
              "passenger_sex           int64\n",
              "passenger_survived      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN_jAhqb0vaJ"
      },
      "source": [
        "## Train-val-test split \n",
        "* Conjunto de entrenamiento \n",
        "* Conjunto de validación\n",
        "* Conjunto de pruebas. en csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTlFNNMlI_nN"
      },
      "source": [
        "### Definiendo Variable dependiente Y y variables independientes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KACS-psxJGws",
        "outputId": "9feb6257-daab-4043-da8b-ea50455b2608"
      },
      "source": [
        "titanic.shape\n",
        "#titanic.head(10)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f-xm9R2I_Ge"
      },
      "source": [
        "X = titanic.iloc[:, 2:8].values #Excluyendo Nombre y ID de variables predictivas\n",
        "y = titanic.iloc[:, 9].values \n",
        "\n",
        "#print(X)\n",
        "#print(y)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEgKWypTLsDs"
      },
      "source": [
        "### Spliting Data en Train, Val, Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5FxgeHR0v1K"
      },
      "source": [
        "#Split 1 para obtener el test Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "#Split 12 para obtener el validation data\n",
        "X_train, X_val, y_train, y_val   = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZapG7LMJ8Hv",
        "outputId": "47ea4e2e-b7b5-4731-ac56-b49b116576d4"
      },
      "source": [
        "print(\"Training Data:\", X_train.shape)\n",
        "print(\"Validation Data:\", X_val.shape)\n",
        "print(\"Testing Data:\", X_test.shape)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data: (534, 6)\n",
            "Validation Data: (178, 6)\n",
            "Testing Data: (179, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBYDzcvQLxXl"
      },
      "source": [
        "### Printing Test to CSV to use in \"production"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yp7bTj2Kiha"
      },
      "source": [
        "pd.DataFrame(X_test).to_csv(\"/content/drive/MyDrive/Statistical Learning O/proyecto_final/X_test.csv\")\n",
        "pd.DataFrame(y_test).to_csv(\"/content/drive/MyDrive/Statistical Learning O/proyecto_final/y_test.csv\")"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG0tZq-T0v86"
      },
      "source": [
        "## Ensemble learning:\n",
        "Se aplicará ensemble learning para crear una \"votación mayoritaria\" con distintos tipos de modelos, con el objetivo de simplificar el problema 2 de estos modelos se harán usando scikit-learn y su función   .fit(x,y) \n",
        "\n",
        "**Recordar  hacer muestreo bootstrap**\n",
        "\n",
        "El ensamble estará compuesto de : \n",
        "\n",
        "*   Árbol de decisión con sklearn\n",
        "*   SVM con sklearn\n",
        "*   Naive bayes con numpy y/o pandas\n",
        "*   Reg. logística binaria(sigmoid): en Tensorflow con regularización (probar L1, L2 y distintos valores del factor de regularización y elegir el mejor) y mini-batch gradient descent usando tamaño de mini-batch como hyper-parametro.\n",
        "\n",
        "Se recomienda crear una función de Python para el entrenamiento de  cada tipo de modelo que reciba los parámetros adecuados para cada uno y devuelva el modelo entrenado y cualquier otra información necesaria y relevante\n",
        "Por ejemplo para SVM:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def train_SVM(X,Y, C,lr ):\n",
        "  …\n",
        "  …\n",
        "  return svm_model\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzjuInTyM2CS"
      },
      "source": [
        "### Arbol de Decisión con sklearn (Función Simple)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT4lJFg0M5b_"
      },
      "source": [
        "def train_decTree(X_train,y_train,max_depth_par,filename):\n",
        "  global dt\n",
        "  dt = DecisionTreeClassifier(criterion = 'entropy', max_depth = max_depth_par, random_state = 0)\n",
        "  dt.fit(X_train, y_train)\n",
        "  print('[5]Decision Tree Classifier Training Accuracy:', dt.score(X_train, y_train))\n",
        "  # save the model to disk\n",
        "  filename = ('/content/drive/MyDrive/Statistical Learning O/proyecto_final/models/%s.csv' % (filename))\n",
        "  joblib.dump(dt, filename)\n",
        "  return dt\n",
        "\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liFu8zLuwHug",
        "outputId": "ba2a75d6-cc58-43ce-efee-b332ba0c5c11"
      },
      "source": [
        "max_depth_par = 3\n",
        "filename = 'test1'\n",
        "\n",
        "train_decTree(X_train,y_train,max_depth_par,filename)\n",
        "Y_val_dt = dt.predict(X_val)\n",
        "dt_accuracy = accuracy_score(y_val,Y_val_dt)\n",
        "print('decision tree validation score:',dt_accuracy )\n",
        "#joblib.dump(model, 'svm_lr=0.01_reg=0.1_var1_var2_var3.pkl')\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5]Decision Tree Classifier Training Accuracy: 0.7303370786516854\n",
            "decision tree validation score: 0.7640449438202247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMQPzWwhfUgp",
        "outputId": "03a5eab6-2bad-4b5c-9726-291e21d7f7a5"
      },
      "source": [
        ""
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6256983240223464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZolxEuT9M53U"
      },
      "source": [
        "### SVM con sklearn (Función Simple)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3q8WgYYM-Af"
      },
      "source": [
        "def train_SVM(X_train,y_train,random_state_var):\n",
        "  global svc_lin\n",
        "  svc_lin = SVC(kernel = 'linear', random_state = random_state_var )\n",
        "  svc_lin.fit(X_train, y_train)\n",
        "  print('[2]Support Vector Machine (Linear Classifier) Training Accuracy:', svc_lin.score(X_train, y_train))\n",
        "  return svc_lin\n",
        "  \n",
        "\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIChn3JYwaYZ",
        "outputId": "05b8df79-9760-4892-f475-1d03c4c446b6"
      },
      "source": [
        "random_state_var = 0\n",
        "train_SVM(X_train,y_train,random_state_var)\n",
        "Y_val_svm = svc_lin.predict(X_val)\n",
        "svm_accuracy = accuracy_score(y_val,Y_val_svm)\n",
        "print('SVM validation score:',svm_accuracy )\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]Support Vector Machine (Linear Classifier) Training Accuracy: 0.7059925093632958\n",
            "SVM validation score: 0.7640449438202247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIQU0sj2M-Qd"
      },
      "source": [
        "### Naive Bayes con numpy y/o Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djle8d7cdgg2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdX7KHV70wFA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "b94f6628-0a34-4548-ad5c-198a592d2984"
      },
      "source": [
        "def train_naiveBayese(X,y, epochs,lr ):\n",
        "  …\n",
        "  …\n",
        "  return naiveBayes_model"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-21366bc4778b>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    …\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AISCB7_Ki_pS"
      },
      "source": [
        "class NaiveBayes:\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self._classes = np.unique(y)\n",
        "        n_classes = len(self._classes)\n",
        "\n",
        "        # calculate mean, var, and prior for each class\n",
        "        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
        "        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
        "        self._priors = np.zeros(n_classes, dtype=np.float64)\n",
        "\n",
        "        for i, c in enumerate(self._classes):\n",
        "            X_c = X[y == c]\n",
        "            self._mean[i, :] = X_c.mean(axis=0)\n",
        "            self._var[i, :] = X_c.var(axis=0)\n",
        "            self._priors[i] = X_c.shape[0] / float(n_samples)\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = [self._predict(x) for x in X]\n",
        "        return np.array(y_pred)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        posteriors = [] \n",
        "\n",
        "        # calculate posterior probability for each class\n",
        "        for i, c in enumerate(self._classes):\n",
        "            prior = np.log(self._priors[i])\n",
        "            posterior = np.sum(np.log(self._pdf(i, x)))\n",
        "            posterior = prior + posterior\n",
        "            posteriors.append(posterior)\n",
        "\n",
        "        # return class with highest posterior probability\n",
        "        return self._classes[np.argmax(posteriors)]\n",
        "\n",
        "    def _pdf(self, class_idx, x):\n",
        "        mean = self._mean[class_idx]\n",
        "        var = self._var[class_idx]\n",
        "        numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n",
        "        denominator = np.sqrt(2 * np.pi * var)\n",
        "        return numerator / denominator\n",
        "    \n",
        "    def accuracy(y_true, y_pred):\n",
        "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "        return accuracy\n",
        "    \n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "VN5A7cGLjEQy",
        "outputId": "dc45a5f5-a74a-44e7-bb75-7c48013e20d5"
      },
      "source": [
        "# Testing\n",
        "\n",
        "\n",
        "nb = NaiveBayes()\n",
        "nb.fit(X_train, y_train)\n",
        "predictions = nb.predict(X_test)\n",
        "\n",
        "print(\"Naive Bayes classification accuracy\", accuracy(y_test, predictions))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-18e4561e4ae5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Naive Bayes classification accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYPcGvdKaHRL"
      },
      "source": [
        " epochs =\n",
        " lr = \n",
        "\n",
        "train_naiveBayese(X_train,y_train,random_state_var,epochs,lr)\n",
        "Y_val_naiveBayese = naiveBayes_model.predict(X_val)\n",
        "naiveBayes_model_accuracy = accuracy_score(y_val,Y_val_svm)\n",
        "print('SVM validation score:',svm_accuracy )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr3ImIiWNEoY"
      },
      "source": [
        "### Reg. logística binaria(sigmoid)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hADTOkwfNI31"
      },
      "source": [
        "def train_logReg(X,y, C,lr ):\n",
        "  initializer = tf.contrib.layers.xavier_initializer()\n",
        "  h0 = tf.layers.dense(X, hidden_layers, activation=tf.nn.relu, kernel_initializer=initializer)\n",
        "  # h0 = tf.nn.dropout(h0, 0.95)\n",
        "  h1 = tf.layers.dense(h0, label_count, activation=None)\n",
        "\n",
        "  cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=h1)\n",
        "  cost = tf.reduce_mean(cross_entropy)\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "  # prediction = tf.argmax(h0, 1)\n",
        "  # correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
        "  # accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "  predicted = tf.nn.sigmoid(h1)\n",
        "  correct_pred = tf.equal(tf.round(predicted), Y)\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "\n",
        "  return logReg_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbqvkERu2EDs"
      },
      "source": [
        "# inputs\n",
        "training_epochs = 3000\n",
        "learning_rate = 0.01\n",
        "hidden_layers = feature_count - 1\n",
        "cost_history = np.empty(shape=[1],dtype=float)\n",
        "\n",
        "X = tf.placeholder(tf.float32,[None,feature_count])\n",
        "Y = tf.placeholder(tf.float32,[None,label_count])\n",
        "is_training=tf.Variable(True,dtype=tf.bool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6r7DzsPNKep"
      },
      "source": [
        "### Ensemble learning model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x9Z8Hp7NEzr"
      },
      "source": [
        "def models(X_train,y_train,epochs,max_depth_par):\n",
        "    \n",
        "  #Using SVM Classifier\n",
        "  def train_SVM(X_train,y_train):\n",
        "    svc_lin = SVC(kernel = 'linear', random_state = 0 )\n",
        "    svc_lin.fit(X_train, y_train)\n",
        "    print('[2]Support Vector Machine (Linear Classifier) Training Accuracy:', svc_lin.score(X_train, y_train))\n",
        "    return svc_lin\n",
        "\n",
        "  #Using DecisionTreeClassifier\n",
        "  def train_decTree(X_train,y_train,max_depth_par):\n",
        "    dt = DecisionTreeClassifier(criterion = 'entropy', max_depth = 3, random_state = 0)\n",
        "    dt.fit(X_train, y_train)\n",
        "    print('[5]Decision Tree Classifier Training Accuracy:', dt.score(X_train, y_train))\n",
        "    return dt\n",
        "\n",
        "\n",
        "\n",
        "  #Returning Model accuracy by step\n",
        "  print('SVM Training Accuracy:', svc_lin.score(X_train, y_train))\n",
        "  print('Decision Tree Classifier Training Accuracy:', dt.score(X_train, y_train))\n",
        "  \n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyUShAFUlFbR"
      },
      "source": [
        "class models2:\n",
        "      \n",
        "  #Using SVM Classifier\n",
        "  def train_SVM(self,X_train,y_train):\n",
        "    self.svc_lin = SVC(kernel = 'linear', random_state = 0 )\n",
        "    svc_lin.fit(X_train, y_train)\n",
        "    print('[2]Support Vector Machine (Linear Classifier) Training Accuracy:', svc_lin.score(X_train, y_train))\n",
        "    return self.svc_lin\n",
        "\n",
        "  #Using DecisionTreeClassifier\n",
        "  def train_decTree(self,X_train,y_train,max_depth_par):\n",
        "    self.dt = DecisionTreeClassifier(criterion = 'entropy', max_depth = 3, random_state = 0)\n",
        "    dt.fit(X_train, y_train)\n",
        "    print('[5]Decision Tree Classifier Training Accuracy:', dt.score(X_train, y_train))\n",
        "    return self.dt\n",
        "\n",
        "\n",
        "\n",
        "  #Returning Model accuracy by step\n",
        "  print('SVM Training Accuracy:', svc_lin.score(X_train, y_train))\n",
        "  print('Decision Tree Classifier Training Accuracy:', dt.score(X_train, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhs1pP_0XoS2",
        "outputId": "5ea6542d-914e-4d6c-803e-b4e300d3c11d"
      },
      "source": [
        "models = models(X_train,y_train,epochs = 0,max_depth_par=4)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Training Accuracy: 0.7059925093632958\n",
            "Decision Tree Classifier Training Accuracy: 0.7303370786516854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvqInAa41VTY"
      },
      "source": [
        "Cada vez que se entrena un modelo ( si se usan funciones como la anterior, cada vez que se ejecuta una de estas funciones) corresponde a un experimento, y para cada experimento(o llamada a una de las funciones):\n",
        "\n",
        "\n",
        "Debemos crear la cadena de configuración que describa cómo se realizó cada experimento,  variables usadas, valores de hyper-parámetros y tipo de modelo usado (similar al config string que hemos usado en tensorboard)    por ejemplo:\n",
        "Se entrena un regresión .logística con lr=0.01 ,factor de regularización = 0.1 usando las variables variables var1,var2,var3, la cadena podría ser: regLog_lr=0.01_reg=0.1_var1_var2_var3\n",
        "Esta cadena nos servirá después para identificar cada experimento, y anotar en una bitácora( excel o csv)  las métricas de evaluación de cada uno.\n",
        "Cada uno de los 4 tipos de modelos pueden requerir más de 1 experimento, con distintos hyper-parámetros o variables usadas, diagnosticamos overfitting u underfitting y realizamos acciones para atacarlos.\n",
        "Por cada experimento debemos guardar en un excel o csv la cadena de configuración y las métricas de evaluación : accuracy,error, precisión,recall,f1-score , estas serán evaluados en el dataset de entrenamiento y el de validación. Es posible usar sklearn(o cualquier otro método que facilite el cálculo) para las métricas de evaluación y Pandas para guardar el csv o excel.\n",
        "Este excel o csv no debe ser sobreescrito  en cada experimento si no que deben agregarse nuevas filas, esta será la bitácora de experimentos. \n",
        "Por cada experimento debemos guardar el modelo correspondiente identificandolo con su cadena de configuración, por ejemplo :\n",
        "con sklearn para guardar un modelo \"model\" del experimento svm_lr=0.01_reg=0.1_var1_var2_var3 se puede usar:\n",
        "\t\tfrom sklearn.externals import joblib\n",
        "\t\n",
        "\t\tjoblib.dump(model, 'svm_lr=0.01_reg=0.1_var1_var2_var3.pkl')\n",
        "Con tensorflow podemos ejecutar en la session los parámetros entrenables(al terminar el entrenamiento) y asignarlos a un tensor de Numpy llamado W,\n",
        "luego podemos guardar el tensor de parámetros del modelo  con  dump()\n",
        "W = session.run(parametros,feed_dict).\n",
        "(Tensorflow tiene sus propios métodos de export y deploy, convenientes para modelos mas complejos (como modelos profundos) , se debe investigar y anotar en markdown conclusiones sobre este tema, en caso de aplicarlas se tomará como puntos extra).\n",
        "\n",
        "\n",
        "W.dump(\"regLog_lr=0.01_reg=0.1_var1_var2_var3.npy\")\n",
        " Con numpy (para el clasificador de bayes) podemos también usar dump (o si se usa pandas usar to_csv por ejemplo)\n",
        "\n",
        "\n",
        "Luego de haber ejecutado ,evaluado, y guardado varios experimentos,elegimos para cada tipo de modelo el mejor basado en las métricas de evaluación sobre los datos de validación. (recordar la exactitud deseada)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEF8fdsk2QYT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQFO_C5t2QyH"
      },
      "source": [
        "## Investigar la técnica: k-fold cross validation \n",
        "\n",
        "agregando en markdown una descripción de esta y como se pudo haber aplicado en este proyecto (No debemos aplicarla al proyecto , solo describir la técnica y cómo se podría aplicar) . \n",
        "\n",
        "Por ejemplo: https://towardsdatascience.com/why-and-how-to-cross-validate-a-model-d6424b45261f . \n",
        "\n",
        "Si esta es aplicada se tomará como puntuación extra\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM6I7bnMoF-w"
      },
      "source": [
        "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "# create the sub models\n",
        "estimators = []\n",
        "model1 = LogisticRegression()\n",
        "estimators.append(('logistic', model1))\n",
        "model2 = DecisionTreeClassifier()\n",
        "estimators.append(('cart', model2))\n",
        "model3 = SVC()\n",
        "estimators.append(('svm', model3))\n",
        "# create the ensemble model\n",
        "ensemble = VotingClassifier(estimators)\n",
        "results = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZV4UL2w2Ylp"
      },
      "source": [
        "def modelVoting (X_train,y_train,max_depth_par):\n",
        "  \n",
        "  #Appying Kfold\n",
        "  seed = 7\n",
        "  kfold = model_selection.KFold(n_splits=10)                              \n",
        "  #Creating dictionary of Models \n",
        "  estimators = [] \n",
        "\n",
        "  #Using SVM Classifier\n",
        "  def train_SVM(X_train,y_train):\n",
        "    svc_lin = SVC(kernel = 'linear')\n",
        "    svc_lin.fit(X_train, y_train)\n",
        "    return svc_lin\n",
        "\n",
        "  #Using DecisionTreeClassifier\n",
        "  def train_decTree(X_train,y_train,max_depth_par):\n",
        "    dt = DecisionTreeClassifier(criterion = 'entropy', max_depth = 3)\n",
        "    dt.fit(X_train, y_train)\n",
        "    return dt\n",
        "\n",
        "  #Using GaussianNB method of naïve_bayes\n",
        "  #def train_naive_bayes(X_train,y_train):\n",
        "   # nb = GaussianNB()\n",
        "   # nb.fit(X_train, Y_train)\n",
        "   # return nb\n",
        "\n",
        "  #Using Logistic Regression Algorithm to the Training Set\n",
        "  #def logReg(X_train,y_train):\n",
        "    #logReg = LogisticRegression()\n",
        "    #logReg.fit(X_train, Y_train)\n",
        "    #return logReg\n",
        "\n",
        "  # create the ensemble model\n",
        "  estimators.append(('svm', svc_lin))\n",
        "  estimators.append(('dt', dt))\n",
        "  ensemble = VotingClassifier(estimators)\n",
        "  #estimators.append(('naive_bayes', nb))\n",
        "  #estimators.append(('log', logReg))\n",
        "  results = model_selection.cross_val_score(ensemble, X_train, y_train, cv=kfold)\n",
        "  print(results.mean())"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5VSrE5YulGY",
        "outputId": "eb9a05ac-0beb-4800-ea7a-506efe4362b5"
      },
      "source": [
        "modelVoting (X_train,y_train,3)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6910202655485673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MWudgS-2Yzh"
      },
      "source": [
        "## Prueba/Evaluación final:\n",
        "\n",
        "Dada el conjunto de observaciones X de el conjunto de pruebas y los 4 modelos elegidos:\n",
        "\t\n",
        "Predecir sobre estas usando el mejor modelo de cada tipo elegido en el punto anterior.\n",
        " Combinar los resultados de las predicciones en una predicción final(moda de resultados individuales)\n",
        "Generar una tabla de predicciones como el ejemplo x y crear un dataframe de Pandas con los resultados.\n",
        "Calcular métricas de evaluación comparando los Y reales del conjunto de pruebas, contra él Y que se obtuvo de combinar las predicciones individuales del modelo.\n",
        "Similar al paso anterior, generar una tabla de métricas de evaluación y crear un dataframe de pandas para mostrar el resultado final.\n",
        "\n",
        "\n",
        "Si en la evaluación final, no se obtiene la exactitud mínima deseada, volver a la fase de experimentación .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8iWH36y2cVg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbPChuHw2chP"
      },
      "source": [
        "## Conclusiones\n",
        "Agregar sección de conclusiones y recomendaciones (incluyendo opiniones,experiencias ,dificultades y lecciones aprendidas)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTEogGUC2lev"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}