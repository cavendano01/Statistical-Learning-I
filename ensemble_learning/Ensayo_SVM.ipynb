{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensayo SVM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPzGtVTijSI9LeY6HcROtuT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cavendano01/Statistical-Learning-I/blob/main/ensemble_learning/Ensayo_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Fz3F_U8IAi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucFy3W2C8Nqf"
      },
      "source": [
        "## hipótesis de SVM\n",
        "La clasificación de vectores de soporte se basa en  intentar clasificar los  datos  en varias clases objetivo. Si las clases en nuestros datos de entrenamiento pueden estar separadas por una línea o algún límite, entonces podemos clasificar los datos dependiendo de qué lado de este límite de decisión se encuentran los datos.\n",
        "\n",
        "Básicamente estamos utilizando SVM para definir dos vectores que se convierten en los límites de una banda dónde la línea de clasificación se separa por dos \"carriles\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgV2ymfD8N2N"
      },
      "source": [
        "## función de costo\n",
        "\n",
        "La función de coste se utiliza para entrenar al SVM. Al minimizar el valor de J (theta), podemos asegurarnos de que la SVM sea lo más precisa posible. En la ecuación, las funciones cost1 y cost0 se refieren al costo de un ejemplo donde y = 1 y el costo de un ejemplo donde y = 0. Para las SVM, el costo está determinado por las funciones del kernel (similitud).\n",
        "\n",
        " ![picture](https://github.com/cavendano01/Statistical-Learning-I/blob/main/ensemble_learning/images/cost.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiReVEz98N_M"
      },
      "source": [
        "## Algoritmo de aprendizaje/entrenamiento\n",
        "\n",
        "Una de las implementaciones más sencillas es con scikit learn que toma un Y univariable y un X con multiples columnas para definir el mejor predictor de clasificación "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e_Uw49l8WWw"
      },
      "source": [
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3,random_state=109) # 70% training and 30% test\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0-tx_jM-ems"
      },
      "source": [
        "Usando uno de los datasets en scikit lear realizaremos un SVM linear que intentara clasificar entre positivo y negativo el diagnostico de cancer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAlfv5qF-eLK",
        "outputId": "380cdbd5-1db6-4e95-e8fa-c12f3145ec1e"
      },
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jja-sBEYGgY8"
      },
      "source": [
        "Con solamente dos líneas de códio obtenemos un resumen de la clasificación de SVC (SVM linear) y hemos entrenado nuestro modelo. Ya que utiliza un resultado entre si y no, el modelo es rápido de entrenar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSgUEKyY-lXG",
        "outputId": "41ab154a-ea05-40cc-d4bd-bc9050b4254f"
      },
      "source": [
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pColaD1k8Wz4"
      },
      "source": [
        "##Propiedades, similitudes, diferencias ,ventajas y desventajas sobre otros algoritmos y modelos.\n",
        "\n",
        "### Ventajas\n",
        "Los clasificadores SVM ofrecen una buena precisión y realizan una predicción más rápida en comparación con el algoritmo Naïve Bayes. También usan menos memoria porque usan un subconjunto de puntos de entrenamiento en la fase de decisión. SVM funciona bien con un claro margen de separación y con un gran espacio dimensional.\n",
        "\n",
        "### Desventajas\n",
        "SVM no es adecuado para grandes conjuntos de datos debido a su alto tiempo de entrenamiento y también lleva más tiempo en el entrenamiento en comparación con Naïve Bayes. Funciona mal con clases superpuestas y también es sensible al tipo de kernel utilizado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2LXjMRu8Zja"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdOMX9k48bkW"
      },
      "source": [
        "## Kernel-trick/basis functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJLA0zhj8bbr"
      },
      "source": [
        "La función principal del kernel es transformar los datos de entrada del conjunto de datos en la forma requerida. Hay varios tipos de funciones, como la función de base lineal, polinomial y radial (RBF). Polinomio y RBF son útiles para hiperplano no lineal. Los núcleos polinomiales y RBF calculan la línea de separación en la dimensión superior. En algunas de las aplicaciones, se sugiere usar un kernel más complejo para separar las clases que son curvas o no lineales. Esta transformación puede conducir a clasificadores más precisos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRaeTJZxENmV"
      },
      "source": [
        "El \"Kernel Trick\"  proporciona una solución a este problema. El \"truco\" es que los métodos del núcleo representan los datos solo a través de un conjunto de comparaciones de similitud por pares entre las observaciones de datos originales x (con las coordenadas originales en el espacio dimensional inferior), en lugar de aplicar explícitamente las transformaciones ϕ (x) y representar el datos por estas coordenadas transformadas en el espacio de características de dimensión superior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx0RDqzhENVH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7JKLvO-8bCh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}